## 중간 보고서: 얼굴 감정 인식 연구

### 1. 서론

본 보고서는 얼굴 감정 인식 연구의 중간 진행 상황을 요약하고 있습니다. 최종 목표는 이미지 데이터로부터 얼굴 표정을 분석하여 감정을 정확하게 분류하는 모델을 개발하는 것입니다. 현재까지 Convolutional Neural Network (CNN) 기반 모델을 활용한 실험을 완료하였으며, 향후 Hybrid CNN-Transformer 모델을 구축 및 실행할 계획입니다.

### 2. 배경 및 목표

얼굴 감정 인식은 인간-컴퓨터 상호작용, 보안 시스템, 헬스케어 등 다양한 분야에서 중요한 기술입니다. 본 연구는 이미지 기반 얼굴 표정 데이터를 이용하여 기본적인 감정(예: 행복, 슬픔, 분노, 놀람, 공포, 혐오, 중립)을 분류하는 것을 목표로 합니다.

### 3. 연구 내용 및 진행 상황

#### 3.1. 데이터셋

본 연구에서는 [**얼굴 이미지**] 데이터셋을 사용하였습니다. 해당 데이터셋은 다양한 조명 조건, 얼굴 각도, 개인에 걸쳐 수집된 얼굴 이미지와 그에 해당하는 감정 레이블로 구성되어 있습니다. 데이터셋의 구성은 다음과 같습니다.

* 총 이미지 수: [**35,887**]
* 클래스 수: 7 (행복, 슬픔, 분노, 놀람, 공포, 혐오, 중립)
* 훈련 데이터 수: [**22,968**]
* 검증 데이터 수: [**5,741**]
* 테스트 데이터 수: [**7,178**]
* 이미지 크기: 48x48 픽셀 (그레이스케일/컬러 여부 명시)

#### 3.2. CNN 기반 모델 실험 결과

기존 연구 및 얼굴 감정 인식 분야에서 CNN이 효과적인 성능을 보여왔기에, 기본적인 CNN 모델을 구축하여 실험을 진행하였습니다.

* **모델 구조:**
    * [**2D CNN Model with BatchNormalization, Dropout, MaxPooling2D, Flatten, Dense**]
    * 활성화 함수: ReLU
    * 최종 출력 레이어: Softmax (7개 클래스)
* **학습 설정:**
    * 손실 함수: Categorical Cross-entropy
    * 옵티마이저: Adam
    * 배치 크기: 32
    * 에포크 수: 10
* **실험 결과:**
    * 훈련 정확도: [**74 (%)**]
    * 검증 정확도: [**78 (%)**]
    * 테스트 정확도: [**54 (%)**]
    * [**현재 과적합 가능성이 높으며, 규제가 필요**]

#### 3.3. Hybrid CNN-Transformer 모델 실행 계획

CNN 기반 모델의 한계를 극복하고 성능 향상을 위해 Hybrid CNN-Transformer 모델을 구축하여 실험할 예정입니다. 해당 모델은 CNN을 통해 이미지의 지역적인 특징을 추출하고, Transformer의 Self-Attention 메커니즘을 활용하여 이미지 내의 장거리 의존성을 모델링하는 것을 목표로 합니다.

* **모델 구조 (예상):**
    1.  **CNN 백본:** [**사용할 CNN 백본 간략히 언급 (예: VGG, ResNet의 일부 레이어)**]을 이용하여 입력 이미지로부터 특징 맵(feature map) 추출.
    2.  **패치 임베딩:** 추출된 특징 맵을 일련의 패치로 분할하고, 각 패치를 선형 투영하여 Transformer의 입력 형태에 맞게 임베딩.
    3.  **Transformer 인코더:** 여러 개의 Transformer 인코더 레이어를 쌓아 패치 임베딩 간의 관계 학습. Self-Attention 메커니즘을 통해 이미지 내의 감정 관련 중요한 영역 간의 상호작용을 모델링.
    4.  **분류 헤드:** Transformer 인코더의 출력을 Pooling 등의 방식으로 집계한 후, Fully Connected 레이어를 거쳐 최종 감정 분류 결과를 출력 (Softmax 활성화 함수 사용).
* **실험 계획:**
    * 사전 학습된 [**사전 학습 모델 사용 여부 및 이름 명시 (예: ImageNet으로 학습된 ViT 모델의 일부)**] 모델의 가중치 초기화 활용 여부 검토.
    * 다양한 하이퍼파라미터 조합 (학습률, 배치 크기, Transformer 레이어 수 등)에 대한 실험 진행.
    * CNN 백본의 구조 및 Transformer 인코더의 설정 변화에 따른 성능 비교 분석.

### 4. 향후 계획

* Hybrid CNN-Transformer 모델 구축 및 학습 코드 구현.
* 모델 학습 및 검증 데이터셋을 이용한 성능 평가.
* 테스트 데이터셋을 이용한 최종 성능 측정 및 분석.
* 결과 분석을 바탕으로 모델 개선 및 추가 실험 진행 여부 결정.
* 최종 보고서 작성.

### 5. 결론 (현재까지)

현재까지 CNN 기반 모델을 활용한 실험을 통해 얼굴 감정 인식의 기본적인 성능을 확인했습니다. Hybrid CNN-Transformer 모델은 이미지 내의 공간적 특징과 장거리 의존성을 효과적으로 모델링하여 CNN 기반 모델의 성능을 능가할 것으로 기대됩니다. 향후 계획된 실험들을 통해 최종 목표 달성을 위해 노력할 것입니다.